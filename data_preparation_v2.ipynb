{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb2994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f13646c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths - UPDATE THESE TO YOUR ABCD DATA LOCATION\n",
    "ABCD_DATA_PATH = \"/path/to/abcd/data\"  # UPDATE THIS PATH\n",
    "OUTPUT_DIR = \"/Users/chloehampson/Desktop/hippo-amyg-depression/derivatives\"\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6536c1a4",
   "metadata": {},
   "source": [
    "## 1. Load ABCD Data Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8b6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load ABCD tables\n",
    "def load_abcd_table(table_name, data_path=ABCD_DATA_PATH):\n",
    "    \"\"\"\n",
    "    Load an ABCD data table.\n",
    "    Tries multiple common file formats.\n",
    "    \"\"\"\n",
    "    extensions = ['.csv', '.txt', '.tsv']\n",
    "    \n",
    "    for ext in extensions:\n",
    "        filepath = os.path.join(data_path, f\"{table_name}{ext}\")\n",
    "        if os.path.exists(filepath):\n",
    "            if ext == '.tsv':\n",
    "                return pd.read_csv(filepath, sep='\\t', low_memory=False)\n",
    "            else:\n",
    "                return pd.read_csv(filepath, low_memory=False)\n",
    "    \n",
    "    print(f\"Warning: Could not find table {table_name}\")\n",
    "    return None\n",
    "\n",
    "print(\"Table loading function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b4b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data tables - UPDATE table names based on your ABCD data release\n",
    "\n",
    "# Demographics\n",
    "demo_df = load_abcd_table('ab_p_demo')\n",
    "static_df = load_abcd_table('ab_g_stc')\n",
    "dynamic_df = load_abcd_table('ab_g_dyn')\n",
    "\n",
    "# Family Environment Scale\n",
    "fes_df = load_abcd_table('fc_p_fes')\n",
    "\n",
    "# Cultural & Social Environment\n",
    "meim_y_df = load_abcd_table('fc_y_meim')\n",
    "meim_p_df = load_abcd_table('fc_p_meim')\n",
    "nbhsoc_df = load_abcd_table('le_l_nbhsoc')\n",
    "srpf_df = load_abcd_table('fc_y_srpf')\n",
    "\n",
    "# SES measures\n",
    "coi_df = load_abcd_table('le_l_coi')\n",
    "\n",
    "# Depression measures\n",
    "cbcl_df = load_abcd_table('mh_p_cbcl')\n",
    "ysr_df = load_abcd_table('mh_y_ysr')\n",
    "ksads_dep_p_df = load_abcd_table('mh_p_ksads__dep')\n",
    "ksads_dep_y_df = load_abcd_table('mh_y_ksads__dep')\n",
    "\n",
    "# MRI Quality Control\n",
    "mri_qc_df = load_abcd_table('mr_y_qc')\n",
    "\n",
    "# N-back task fMRI data\n",
    "nback_aseg_df = load_abcd_table('mri_y_tfmr_nback_aseg')\n",
    "\n",
    "print(\"Data tables loaded (or attempted to load).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890ec11c",
   "metadata": {},
   "source": [
    "## 2. Define Variable Lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5984a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject identifier\n",
    "SUBJECT_ID = 'src_subject_id'\n",
    "SESSION_ID = 'eventname'\n",
    "\n",
    "# ----- COVARIATE VARIABLES -----\n",
    "COVARIATES = {\n",
    "    'age': 'ab_p_demo_age',\n",
    "    'sex': 'ab_g_stc__cohort_sex',\n",
    "    'ethnicity': 'ab_g_stc__cohort_ethnrace__meim',\n",
    "    'race': 'ab_g_stc__cohort_race__nih',\n",
    "    'site': 'ab_g_dyn__design_site',\n",
    "    'family_id': 'ab_g_stc__design_id__fam',\n",
    "}\n",
    "\n",
    "print(f\"Covariates defined: {len(COVARIATES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17619da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- SOCIOENVIRONMENTAL VARIABLES (PLSC Block 1 / X) -----\n",
    "\n",
    "# Family Environment\n",
    "FAMILY_ENV_VARS = [\n",
    "    'fc_p_fes__cohes_mean',      # Family cohesion\n",
    "    'fc_p_fes__confl_mean',      # Family conflict\n",
    "    'fc_p_fes__expr_mean',       # Family expression\n",
    "    'fc_p_fes__intelcult_mean',  # Intellectual/cultural orientation\n",
    "    'fc_p_fes__org_mean',        # Family organization\n",
    "    'fc_p_fes__rec_mean',        # Active-recreational orientation\n",
    "]\n",
    "\n",
    "# Cultural & Social Environment\n",
    "CULTURAL_SOCIAL_VARS = [\n",
    "    'fc_y_meim_mean',                          # MEIM Youth\n",
    "    'fc_p_meim_mean',                          # MEIM Parent\n",
    "    'le_l_nbhsoc__addr1__factor3_score',       # Neighborhood ethnic/immigrant\n",
    "    'fc_y_srpf__env_mean',                     # School environment\n",
    "]\n",
    "\n",
    "# Socioeconomic Status\n",
    "SES_VARS = [\n",
    "    'le_l_nbhsoc__addr1__factor1_score',       # Neighborhood disadvantage\n",
    "    'le_l_nbhsoc__addr1__aff_score',           # Neighborhood affluence\n",
    "    'le_l_coi__addr1__coi__total__metro_score',# Child Opportunity Index\n",
    "    'ab_p_demo__income__hhold_001',            # Household income\n",
    "    'ab_g_dyn__cohort_edu__cgs',               # Caregiver education\n",
    "]\n",
    "\n",
    "# Combine all socioenvironmental variables\n",
    "SOCIOENV_VARS = FAMILY_ENV_VARS + CULTURAL_SOCIAL_VARS + SES_VARS\n",
    "\n",
    "print(f\"\\nTotal SOCIOENVIRONMENTAL variables: {len(SOCIOENV_VARS)}\")\n",
    "print(\"\\n--- Family Environment ---\")\n",
    "for v in FAMILY_ENV_VARS: print(f\"  {v}\")\n",
    "print(\"\\n--- Cultural/Social ---\")\n",
    "for v in CULTURAL_SOCIAL_VARS: print(f\"  {v}\")\n",
    "print(\"\\n--- SES ---\")\n",
    "for v in SES_VARS: print(f\"  {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d57c2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- DEPRESSION VARIABLES (PLSC Block 2 / Y) -----\n",
    "\n",
    "DEPRESSION_VARS = [\n",
    "    # Summary scores\n",
    "    'mh_p_cbcl__dsm__dep_sum',      # CBCL Depression (Parent)\n",
    "    'mh_y_ysr__dsm__dep_sum',       # YSR Depression (Youth)\n",
    "    \n",
    "    # Core symptoms - Parent report\n",
    "    'mh_p_ksads__dep__mood__pres_sx',   # Depressed mood (Parent)\n",
    "    'mh_p_ksads__dep__anhed__pres_sx',  # Anhedonia (Parent)\n",
    "    'mh_p_ksads__dep__fatig__pres_sx',  # Fatigue (Parent)\n",
    "    \n",
    "    # Core symptoms - Youth report\n",
    "    'mh_y_ksads__dep__mood__pres_sx',   # Depressed mood (Youth)\n",
    "    'mh_y_ksads__dep__anhed__pres_sx',  # Anhedonia (Youth)\n",
    "    'mh_y_ksads__dep__fatig__pres_sx',  # Fatigue (Youth)\n",
    "]\n",
    "\n",
    "print(f\"Total DEPRESSION variables: {len(DEPRESSION_VARS)}\")\n",
    "for v in DEPRESSION_VARS: print(f\"  {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa50bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- BRAIN VARIABLES: HIPPOCAMPUS & AMYGDALA (Stage 2) -----\n",
    "# N-back task activation - UPDATE based on your ABCD data release\n",
    "\n",
    "# Hippocampus ROIs\n",
    "HIPPOCAMPUS_VARS = [\n",
    "    'tfmri_nback_all_beta_l_hippocampus',\n",
    "    'tfmri_nback_all_beta_r_hippocampus',\n",
    "    'tfmri_nback_2b_face_beta_l_hippocampus',\n",
    "    'tfmri_nback_2b_face_beta_r_hippocampus',\n",
    "    'tfmri_nback_2b_place_beta_l_hippocampus',\n",
    "    'tfmri_nback_2b_place_beta_r_hippocampus',\n",
    "]\n",
    "\n",
    "# Amygdala ROIs\n",
    "AMYGDALA_VARS = [\n",
    "    'tfmri_nback_all_beta_l_amygdala',\n",
    "    'tfmri_nback_all_beta_r_amygdala',\n",
    "    'tfmri_nback_2b_face_beta_l_amygdala',\n",
    "    'tfmri_nback_2b_face_beta_r_amygdala',\n",
    "    'tfmri_nback_2b_place_beta_l_amygdala',\n",
    "    'tfmri_nback_2b_place_beta_r_amygdala',\n",
    "]\n",
    "\n",
    "BRAIN_VARS = HIPPOCAMPUS_VARS + AMYGDALA_VARS\n",
    "\n",
    "print(f\"Total BRAIN variables: {len(BRAIN_VARS)}\")\n",
    "print(f\"  Hippocampus: {len(HIPPOCAMPUS_VARS)}\")\n",
    "print(f\"  Amygdala: {len(AMYGDALA_VARS)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6ef0ec",
   "metadata": {},
   "source": [
    "## 3. Merge Data Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7858643",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_abcd_tables(tables_dict, on_cols=['src_subject_id', 'eventname'], how='inner'):\n",
    "    \"\"\"\n",
    "    Merge multiple ABCD tables on subject ID and eventname.\n",
    "    \"\"\"\n",
    "    merged_df = None\n",
    "    \n",
    "    for name, df in tables_dict.items():\n",
    "        if df is None:\n",
    "            print(f\"Skipping {name} - DataFrame is None\")\n",
    "            continue\n",
    "            \n",
    "        available_cols = [col for col in on_cols if col in df.columns]\n",
    "        \n",
    "        if len(available_cols) == 0:\n",
    "            print(f\"Skipping {name} - No merge columns found\")\n",
    "            continue\n",
    "        \n",
    "        if merged_df is None:\n",
    "            merged_df = df.copy()\n",
    "            print(f\"Initialized with {name}: {len(merged_df)} rows\")\n",
    "        else:\n",
    "            merged_df = merged_df.merge(df, on=available_cols, how=how, suffixes=('', f'_{name}'))\n",
    "            print(f\"After merging {name}: {len(merged_df)} rows\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Create dictionary of tables to merge\n",
    "tables_to_merge = {\n",
    "    'demo': demo_df,\n",
    "    'static': static_df,\n",
    "    'dynamic': dynamic_df,\n",
    "    'fes': fes_df,\n",
    "    'meim_y': meim_y_df,\n",
    "    'meim_p': meim_p_df,\n",
    "    'nbhsoc': nbhsoc_df,\n",
    "    'srpf': srpf_df,\n",
    "    'coi': coi_df,\n",
    "    'cbcl': cbcl_df,\n",
    "    'ysr': ysr_df,\n",
    "    'ksads_dep_p': ksads_dep_p_df,\n",
    "    'ksads_dep_y': ksads_dep_y_df,\n",
    "    'mri_qc': mri_qc_df,\n",
    "    'nback_aseg': nback_aseg_df,\n",
    "}\n",
    "\n",
    "# Remove None entries\n",
    "tables_to_merge = {k: v for k, v in tables_to_merge.items() if v is not None}\n",
    "print(f\"\\nTables available for merging: {list(tables_to_merge.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108dd67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge all tables\n",
    "# NOTE: Uncomment when data is loaded\n",
    "# merged_df = merge_abcd_tables(tables_to_merge)\n",
    "\n",
    "print(\"NOTE: Uncomment the merge function call once data is loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4135df66",
   "metadata": {},
   "source": [
    "## 4. Select Timepoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657309d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define timepoint of interest\n",
    "TIMEPOINT = 'ses-02A'  # 2-year follow-up - UPDATE AS NEEDED\n",
    "\n",
    "# Filter to selected timepoint\n",
    "# Uncomment when merged_df is available\n",
    "\n",
    "# if 'eventname' in merged_df.columns:\n",
    "#     analysis_df = merged_df[merged_df['eventname'] == TIMEPOINT].copy()\n",
    "#     print(f\"Subjects at {TIMEPOINT}: {len(analysis_df)}\")\n",
    "# else:\n",
    "#     analysis_df = merged_df.copy()\n",
    "\n",
    "print(f\"Selected timepoint: {TIMEPOINT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24aa5e06",
   "metadata": {},
   "source": [
    "## 5. Quality Control & Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3406b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_qc_filters(df, motion_threshold=0.5, motion_var='tfmri_nback_all_meanmotion', qc_var='imgincl_nback_include'):\n",
    "    \"\"\"Apply quality control filters for neuroimaging data.\"\"\"\n",
    "    n_initial = len(df)\n",
    "    \n",
    "    if qc_var in df.columns:\n",
    "        df = df[df[qc_var] == 1]\n",
    "        print(f\"After QC inclusion filter: {len(df)} ({n_initial - len(df)} removed)\")\n",
    "    \n",
    "    if motion_var in df.columns:\n",
    "        n_before = len(df)\n",
    "        df = df[df[motion_var] <= motion_threshold]\n",
    "        print(f\"After motion filter: {len(df)} ({n_before - len(df)} removed)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def assess_missing_data(df, variables):\n",
    "    \"\"\"Assess missing data for a list of variables.\"\"\"\n",
    "    missing_info = []\n",
    "    for var in variables:\n",
    "        if var in df.columns:\n",
    "            n_missing = df[var].isna().sum()\n",
    "            pct_missing = (n_missing / len(df)) * 100\n",
    "            missing_info.append({\n",
    "                'variable': var,\n",
    "                'n_missing': n_missing,\n",
    "                'pct_missing': round(pct_missing, 2)\n",
    "            })\n",
    "        else:\n",
    "            missing_info.append({'variable': var, 'n_missing': 'NOT FOUND', 'pct_missing': 'N/A'})\n",
    "    return pd.DataFrame(missing_info)\n",
    "\n",
    "print(\"QC and missing data functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ea64d8",
   "metadata": {},
   "source": [
    "## 6. Create PLSC Dataframes (Separate Blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e1530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plsc_dataframes_separate(df, socioenv_vars, depression_vars, brain_vars, covariate_vars, subject_id='src_subject_id'):\n",
    "    \"\"\"\n",
    "    Create FOUR separate dataframes for the two-stage PLSC analysis:\n",
    "    \n",
    "    Stage 1 PLSC:\n",
    "    1. Socioenvironmental dataframe (Block 1 / X)\n",
    "    2. Depression dataframe (Block 2 / Y)\n",
    "    \n",
    "    Stage 2 (Brain correlation):\n",
    "    3. Brain dataframe (Hippocampus & Amygdala)\n",
    "    \n",
    "    Plus:\n",
    "    4. Covariate dataframe (for residualization)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter to existing variables\n",
    "    existing_socioenv = [v for v in socioenv_vars if v in df.columns]\n",
    "    existing_depression = [v for v in depression_vars if v in df.columns]\n",
    "    existing_brain = [v for v in brain_vars if v in df.columns]\n",
    "    existing_covars = {k: v for k, v in covariate_vars.items() if v in df.columns}\n",
    "    \n",
    "    print(f\"Socioenvironmental variables found: {len(existing_socioenv)}/{len(socioenv_vars)}\")\n",
    "    print(f\"Depression variables found: {len(existing_depression)}/{len(depression_vars)}\")\n",
    "    print(f\"Brain variables found: {len(existing_brain)}/{len(brain_vars)}\")\n",
    "    print(f\"Covariate variables found: {len(existing_covars)}/{len(covariate_vars)}\")\n",
    "    \n",
    "    # Create covariate dataframe\n",
    "    covar_cols = [subject_id] + list(existing_covars.values())\n",
    "    covar_df = df[covar_cols].copy()\n",
    "    covar_df = covar_df.set_index(subject_id)\n",
    "    \n",
    "    # Create SOCIOENVIRONMENTAL dataframe (PLSC Block 1 / X)\n",
    "    socioenv_df = df[[subject_id] + existing_socioenv].copy()\n",
    "    socioenv_df = socioenv_df.set_index(subject_id)\n",
    "    \n",
    "    # Create DEPRESSION dataframe (PLSC Block 2 / Y)\n",
    "    depression_df = df[[subject_id] + existing_depression].copy()\n",
    "    depression_df = depression_df.set_index(subject_id)\n",
    "    \n",
    "    # Create BRAIN dataframe (Stage 2)\n",
    "    brain_df = df[[subject_id] + existing_brain].copy()\n",
    "    brain_df = brain_df.set_index(subject_id)\n",
    "    \n",
    "    return {\n",
    "        'covariates': covar_df,\n",
    "        'socioenv': socioenv_df,\n",
    "        'depression': depression_df,\n",
    "        'brain': brain_df,\n",
    "        'variable_lists': {\n",
    "            'socioenv': existing_socioenv,\n",
    "            'depression': existing_depression,\n",
    "            'brain': existing_brain,\n",
    "            'covariates': existing_covars\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"PLSC dataframe creation function defined (separate blocks).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff468e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PLSC dataframes\n",
    "# Uncomment when analysis_df is available\n",
    "\n",
    "# plsc_data = create_plsc_dataframes_separate(\n",
    "#     analysis_df,\n",
    "#     socioenv_vars=SOCIOENV_VARS,\n",
    "#     depression_vars=DEPRESSION_VARS,\n",
    "#     brain_vars=BRAIN_VARS,\n",
    "#     covariate_vars=COVARIATES\n",
    "# )\n",
    "# \n",
    "# print(\"\\nDataframe shapes:\")\n",
    "# print(f\"  Covariates: {plsc_data['covariates'].shape}\")\n",
    "# print(f\"  Socioenvironmental (PLSC Block 1): {plsc_data['socioenv'].shape}\")\n",
    "# print(f\"  Depression (PLSC Block 2): {plsc_data['depression'].shape}\")\n",
    "# print(f\"  Brain - Hippo/Amyg (Stage 2): {plsc_data['brain'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0daa6d1",
   "metadata": {},
   "source": [
    "## 7. Save Dataframes for R Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c5cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plsc_dataframes(plsc_data, output_dir):\n",
    "    \"\"\"\n",
    "    Save PLSC dataframes to CSV files for R analysis.\n",
    "    Creates FOUR separate files for the two-stage analysis.\n",
    "    \"\"\"\n",
    "    import json\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save covariates\n",
    "    plsc_data['covariates'].to_csv(os.path.join(output_dir, 'covariate.csv'))\n",
    "    print(f\"Saved: covariate.csv {plsc_data['covariates'].shape}\")\n",
    "    \n",
    "    # Save socioenvironmental (PLSC Block 1)\n",
    "    plsc_data['socioenv'].to_csv(os.path.join(output_dir, 'clean-socioenv.csv'))\n",
    "    print(f\"Saved: clean-socioenv.csv {plsc_data['socioenv'].shape}\")\n",
    "    \n",
    "    # Save depression (PLSC Block 2)\n",
    "    plsc_data['depression'].to_csv(os.path.join(output_dir, 'clean-depression.csv'))\n",
    "    print(f\"Saved: clean-depression.csv {plsc_data['depression'].shape}\")\n",
    "    \n",
    "    # Save brain data (Stage 2)\n",
    "    plsc_data['brain'].to_csv(os.path.join(output_dir, 'clean-brain-hippo-amyg.csv'))\n",
    "    print(f\"Saved: clean-brain-hippo-amyg.csv {plsc_data['brain'].shape}\")\n",
    "    \n",
    "    # Save variable lists\n",
    "    with open(os.path.join(output_dir, 'variable_lists.json'), 'w') as f:\n",
    "        json.dump(plsc_data['variable_lists'], f, indent=2)\n",
    "    print(\"Saved: variable_lists.json\")\n",
    "    \n",
    "    print(f\"\\nAll files saved to: {output_dir}\")\n",
    "\n",
    "print(\"Save function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f16c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframes\n",
    "# Uncomment when plsc_data is available\n",
    "\n",
    "# save_plsc_dataframes(plsc_data, OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64b280c",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### Files Created:\n",
    "1. **covariate.csv** - Demographic & nuisance variables for residualization\n",
    "2. **clean-socioenv.csv** - Socioenvironmental factors (PLSC Block 1 / X)\n",
    "3. **clean-depression.csv** - Depression symptoms (PLSC Block 2 / Y)  \n",
    "4. **clean-brain-hippo-amyg.csv** - Hippocampus & Amygdala (Stage 2)\n",
    "5. **variable_lists.json** - Reference file with all variable names\n",
    "\n",
    "### Analysis Flow:\n",
    "```\n",
    "STAGE 1: PLSC\n",
    "   Socioenvironmental (X) ←→ Depression (Y)\n",
    "   → Identifies latent dimensions linking socio factors to depression\n",
    "   → Extract latent variable scores\n",
    "\n",
    "STAGE 2: Brain Correlation  \n",
    "   PLSC Latent Scores ←→ Hippocampus/Amygdala Activation\n",
    "   → Determines brain's role in socio-depression association\n",
    "```\n",
    "\n",
    "### Next Steps:\n",
    "1. Open `hippo_amyg_depression_plsc.Rmd` in RStudio\n",
    "2. Update file paths to point to the derivatives folder\n",
    "3. Run the PLSC analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb630135",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATA PREPARATION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nOutput directory: {OUTPUT_DIR}\")\n",
    "print(\"\\nNext: Run hippo_amyg_depression_plsc.Rmd in R\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
