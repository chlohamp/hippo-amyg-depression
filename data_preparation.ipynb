{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a21b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b70111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths - UPDATE THESE TO YOUR ABCD DATA LOCATION\n",
    "ABCD_DATA_PATH = \"/path/to/abcd/data\"  # UPDATE THIS PATH\n",
    "OUTPUT_DIR = \"/Users/chloehampson/Desktop/hippo-amyg-depression/derivatives\"\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2aa219",
   "metadata": {},
   "source": [
    "## 1. Define All Variables (from ABCD Data Dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2077aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject identifier\n",
    "SUBJECT_ID = 'src_subject_id'\n",
    "SESSION_ID = 'eventname'\n",
    "\n",
    "# =====================================================\n",
    "# COVARIATE VARIABLES (for residualization)\n",
    "# =====================================================\n",
    "COVARIATES = {\n",
    "    'age': 'ab_p_demo_age',                       # Youth's age at data collection\n",
    "    'sex': 'ab_g_stc__cohort_sex',                # Participant's sex\n",
    "    'ethnicity': 'ab_g_stc__cohort_ethnrace__meim',  # Ethno-racial identity (15 levels)\n",
    "    'race': 'ab_g_stc__cohort_race__nih',         # Race (NIH 7 levels)\n",
    "    'site': 'ab_g_dyn__design_site',              # Assessment site\n",
    "    'family_id': 'ab_g_stc__design_id__fam',      # Family ID (for nesting)\n",
    "    # 'head_motion': 'mr_y_qc__mot',              # TBD based on task\n",
    "}\n",
    "\n",
    "print(f\"Covariates: {len(COVARIATES)}\")\n",
    "for k, v in COVARIATES.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccb0f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# SOCIOENVIRONMENTAL VARIABLES (PLSC Block 1 / X)\n",
    "# =====================================================\n",
    "\n",
    "# Family Environment (fc_p_fes)\n",
    "FAMILY_ENV_VARS = [\n",
    "    'fc_p_fes__cohes_mean',      # Family Environment Scale—Cohesion: Mean\n",
    "    'fc_p_fes__confl_mean',      # Family Environment Scale—Conflict: Mean\n",
    "    'fc_p_fes__expr_mean',       # Family Environment Scale—Expression: Mean\n",
    "    'fc_p_fes__intelcult_mean',  # Family Environment Scale—Intellectual/cultural: Mean\n",
    "    'fc_p_fes__org_mean',        # Family Environment Scale—Organization: Mean\n",
    "    'fc_p_fes__rec_mean',        # Family Environment Scale—Activity/recreational: Mean\n",
    "]\n",
    "\n",
    "# Cultural & Social Environment\n",
    "CULTURAL_SOCIAL_VARS = [\n",
    "    'fc_y_meim_mean',                          # Multigroup Ethnic Identity Measure [Youth]: Mean\n",
    "    'fc_p_meim_mean',                          # Multigroup Ethnic Identity Measure [Parent]: Mean\n",
    "    'le_l_nbhsoc__addr1__factor3_score',       # Neighborhood ethnic/immigrant concentration\n",
    "    'fc_y_srpf__env_mean',                     # School Risk & Protective Factors—School environment: Mean\n",
    "]\n",
    "\n",
    "# Socioeconomic Status & Demographics\n",
    "SES_VARS = [\n",
    "    'le_l_nbhsoc__addr1__factor1_score',       # Neighborhood disadvantage score\n",
    "    'le_l_nbhsoc__addr1__aff_score',           # Neighborhood affluence score\n",
    "    'le_l_coi__addr1__coi__total__metro_score',# Child Opportunity Index (metro-normed, 1-100)\n",
    "    'ab_p_demo__income__hhold_001',            # Household income category\n",
    "    'ab_g_dyn__cohort_edu__cgs',               # Highest education across caregivers\n",
    "]\n",
    "\n",
    "# Combine all socioenvironmental\n",
    "SOCIOENV_VARS = FAMILY_ENV_VARS + CULTURAL_SOCIAL_VARS + SES_VARS\n",
    "\n",
    "print(f\"\\nSOCIOENVIRONMENTAL VARIABLES: {len(SOCIOENV_VARS)}\")\n",
    "print(f\"\\n  Family Environment ({len(FAMILY_ENV_VARS)}):\")\n",
    "for v in FAMILY_ENV_VARS: print(f\"    - {v}\")\n",
    "print(f\"\\n  Cultural/Social ({len(CULTURAL_SOCIAL_VARS)}):\")\n",
    "for v in CULTURAL_SOCIAL_VARS: print(f\"    - {v}\")\n",
    "print(f\"\\n  SES ({len(SES_VARS)}):\")\n",
    "for v in SES_VARS: print(f\"    - {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935578e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# DEPRESSION VARIABLES (PLSC Block 2 / Y)\n",
    "# =====================================================\n",
    "\n",
    "DEPRESSION_VARS = [\n",
    "    # Summary scores\n",
    "    'mh_p_cbcl__dsm__dep_sum',      # CBCL [Parent] DSM-5 Depressive problems: Sum\n",
    "    'mh_y_ysr__dsm__dep_sum',       # YSR [Youth] DSM-5 Depressive problems: Sum\n",
    "    \n",
    "    # Core symptoms - Parent report (KSADS)\n",
    "    'mh_p_ksads__dep__mood__pres_sx',   # Depressed mood - Present [Parent]\n",
    "    'mh_p_ksads__dep__anhed__pres_sx',  # Anhedonia - Present [Parent]\n",
    "    'mh_p_ksads__dep__fatig__pres_sx',  # Fatigue - Present [Parent]\n",
    "    \n",
    "    # Core symptoms - Youth report (KSADS)\n",
    "    'mh_y_ksads__dep__mood__pres_sx',   # Depressed mood - Present [Youth]\n",
    "    'mh_y_ksads__dep__anhed__pres_sx',  # Anhedonia - Present [Youth]\n",
    "    'mh_y_ksads__dep__fatig__pres_sx',  # Fatigue - Present [Youth]\n",
    "]\n",
    "\n",
    "print(f\"DEPRESSION VARIABLES: {len(DEPRESSION_VARS)}\")\n",
    "for v in DEPRESSION_VARS:\n",
    "    print(f\"  - {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf90c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# BRAIN VARIABLES - 4 ROIs (Stage 2 - Analyzed Separately)\n",
    "# =====================================================\n",
    "# Emotional N-back task beta weights\n",
    "\n",
    "# Hippocampus: 2-back vs 0-back contrast (working memory load)\n",
    "HIPPOCAMPUS_VARS = {\n",
    "    'hippo_lh': 'mr_y_tfmri__nback__2bv0b__aseg__hc__lh_beta',  # Left hippocampus\n",
    "    'hippo_rh': 'mr_y_tfmri__nback__2bv0b__aseg__hc__rh_beta',  # Right hippocampus\n",
    "}\n",
    "\n",
    "# Amygdala: Emotion vs Neutral face contrast (emotional processing)\n",
    "AMYGDALA_VARS = {\n",
    "    'amyg_lh': 'mr_y_tfmri__nback__emovntf__aseg__ag__lh_beta',  # Left amygdala\n",
    "    'amyg_rh': 'mr_y_tfmri__nback__emovntf__aseg__ag__rh_beta',  # Right amygdala\n",
    "}\n",
    "\n",
    "# Combined dictionary for all brain ROIs\n",
    "BRAIN_ROIS = {**HIPPOCAMPUS_VARS, **AMYGDALA_VARS}\n",
    "\n",
    "# List of variable names for data loading\n",
    "BRAIN_VARS = list(BRAIN_ROIS.values())\n",
    "\n",
    "# Labels for plotting/output\n",
    "BRAIN_ROI_LABELS = {\n",
    "    'mr_y_tfmri__nback__2bv0b__aseg__hc__lh_beta': 'Left Hippocampus (2b>0b)',\n",
    "    'mr_y_tfmri__nback__2bv0b__aseg__hc__rh_beta': 'Right Hippocampus (2b>0b)',\n",
    "    'mr_y_tfmri__nback__emovntf__aseg__ag__lh_beta': 'Left Amygdala (emo>neut)',\n",
    "    'mr_y_tfmri__nback__emovntf__aseg__ag__rh_beta': 'Right Amygdala (emo>neut)',\n",
    "}\n",
    "\n",
    "print(f\"BRAIN ROIs: {len(BRAIN_VARS)} (analyzed separately in Stage 2)\")\n",
    "print(\"\\n  Hippocampus (2-back vs 0-back - working memory):\")\n",
    "for k, v in HIPPOCAMPUS_VARS.items():\n",
    "    print(f\"    - {k}: {v}\")\n",
    "print(\"\\n  Amygdala (emotion vs neutral face - emotional processing):\")\n",
    "for k, v in AMYGDALA_VARS.items():\n",
    "    print(f\"    - {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e6401",
   "metadata": {},
   "source": [
    "## 2. Load ABCD Data Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990c3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_abcd_table(table_name, data_path=ABCD_DATA_PATH):\n",
    "    \"\"\"Load an ABCD data table. Tries .csv, .txt, .tsv extensions.\"\"\"\n",
    "    for ext in ['.csv', '.txt', '.tsv']:\n",
    "        filepath = os.path.join(data_path, f\"{table_name}{ext}\")\n",
    "        if os.path.exists(filepath):\n",
    "            sep = '\\t' if ext == '.tsv' else ','\n",
    "            return pd.read_csv(filepath, sep=sep, low_memory=False)\n",
    "    print(f\"Warning: Could not find table {table_name}\")\n",
    "    return None\n",
    "\n",
    "print(\"Table loading function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6a3f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data tables - UPDATE table names based on your ABCD data release\n",
    "# These are the table names from your data dictionary\n",
    "\n",
    "tables_to_load = {\n",
    "    # Demographics\n",
    "    'ab_p_demo': 'ab_p_demo',       # Parent demographics (age, income)\n",
    "    'ab_g_stc': 'ab_g_stc',         # Static cohort info (sex, race, family ID)\n",
    "    'ab_g_dyn': 'ab_g_dyn',         # Dynamic design info (site, education)\n",
    "    \n",
    "    # Family Environment Scale\n",
    "    'fc_p_fes': 'fc_p_fes',         # Family Environment Scale [Parent]\n",
    "    \n",
    "    # Cultural & Social\n",
    "    'fc_y_meim': 'fc_y_meim',       # MEIM [Youth]\n",
    "    'fc_p_meim': 'fc_p_meim',       # MEIM [Parent]\n",
    "    'le_l_nbhsoc': 'le_l_nbhsoc',   # Neighborhood social\n",
    "    'fc_y_srpf': 'fc_y_srpf',       # School Risk & Protective Factors\n",
    "    \n",
    "    # SES\n",
    "    'le_l_coi': 'le_l_coi',         # Child Opportunity Index\n",
    "    \n",
    "    # Depression\n",
    "    'mh_p_cbcl': 'mh_p_cbcl',       # CBCL [Parent]\n",
    "    'mh_y_ysr': 'mh_y_ysr',         # YSR [Youth]\n",
    "    'mh_p_ksads__dep': 'mh_p_ksads__dep',  # KSADS Depression [Parent]\n",
    "    'mh_y_ksads__dep': 'mh_y_ksads__dep',  # KSADS Depression [Youth]\n",
    "    \n",
    "    # MRI\n",
    "    'mr_y_qc': 'mr_y_qc',           # MRI Quality Control\n",
    "    'mr_y_tfmri__nback__2bv0b__aseg': 'mr_y_tfmri__nback__2bv0b__aseg',  # N-back 2b>0b (hippocampus)\n",
    "    'mr_y_tfmri__nback__emovntf__aseg': 'mr_y_tfmri__nback__emovntf__aseg',  # N-back emo>neut (amygdala)\n",
    "}\n",
    "\n",
    "# Load all tables\n",
    "loaded_tables = {}\n",
    "for name, table in tables_to_load.items():\n",
    "    loaded_tables[name] = load_abcd_table(table)\n",
    "\n",
    "# Check what loaded\n",
    "print(\"\\nTable loading status:\")\n",
    "for name, df in loaded_tables.items():\n",
    "    if df is not None:\n",
    "        print(f\"  ✓ {name}: {len(df)} rows, {len(df.columns)} columns\")\n",
    "    else:\n",
    "        print(f\"  ✗ {name}: NOT FOUND\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe172f8",
   "metadata": {},
   "source": [
    "## 3. Merge Data Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f113eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_abcd_tables(tables_dict, on_cols=['src_subject_id', 'eventname'], how='inner'):\n",
    "    \"\"\"Merge multiple ABCD tables on subject ID and eventname.\"\"\"\n",
    "    merged_df = None\n",
    "    \n",
    "    for name, df in tables_dict.items():\n",
    "        if df is None:\n",
    "            continue\n",
    "            \n",
    "        available_cols = [col for col in on_cols if col in df.columns]\n",
    "        if len(available_cols) == 0:\n",
    "            print(f\"Skipping {name} - No merge columns found\")\n",
    "            continue\n",
    "        \n",
    "        if merged_df is None:\n",
    "            merged_df = df.copy()\n",
    "            print(f\"Initialized with {name}: {len(merged_df)} rows\")\n",
    "        else:\n",
    "            merged_df = merged_df.merge(df, on=available_cols, how=how, suffixes=('', f'_{name}'))\n",
    "            print(f\"After merging {name}: {len(merged_df)} rows\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "# Filter to tables that loaded successfully\n",
    "valid_tables = {k: v for k, v in loaded_tables.items() if v is not None}\n",
    "print(f\"\\nTables available for merging: {len(valid_tables)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab457b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge tables\n",
    "# Uncomment when data is loaded:\n",
    "# merged_df = merge_abcd_tables(valid_tables)\n",
    "# print(f\"\\nFinal merged dataset: {len(merged_df)} rows, {len(merged_df.columns)} columns\")\n",
    "\n",
    "print(\"NOTE: Uncomment the merge function once data is loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453b1a27",
   "metadata": {},
   "source": [
    "## 4. Select Timepoint & Apply QC Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55cf999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select timepoint - many variables available at ses-02A (2-year follow-up)\n",
    "TIMEPOINT = 'ses-02A'  # UPDATE AS NEEDED\n",
    "\n",
    "# Alternative timepoints:\n",
    "# 'ses-00A' = Baseline\n",
    "# 'ses-02A' = 2-year follow-up\n",
    "# 'ses-04A' = 4-year follow-up\n",
    "\n",
    "print(f\"Selected timepoint: {TIMEPOINT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be7939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_qc_filters(df, motion_threshold=0.5, motion_var=None, qc_var=None):\n",
    "    \"\"\"Apply quality control filters for neuroimaging data.\"\"\"\n",
    "    n_initial = len(df)\n",
    "    \n",
    "    if qc_var and qc_var in df.columns:\n",
    "        df = df[df[qc_var] == 1]\n",
    "        print(f\"After QC inclusion: {len(df)} ({n_initial - len(df)} removed)\")\n",
    "    \n",
    "    if motion_var and motion_var in df.columns:\n",
    "        n_before = len(df)\n",
    "        df = df[df[motion_var] <= motion_threshold]\n",
    "        print(f\"After motion filter (≤{motion_threshold}): {len(df)} ({n_before - len(df)} removed)\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Uncomment when data is loaded:\n",
    "# # Filter to timepoint\n",
    "# analysis_df = merged_df[merged_df['eventname'] == TIMEPOINT].copy()\n",
    "# print(f\"Subjects at {TIMEPOINT}: {len(analysis_df)}\")\n",
    "# \n",
    "# # Apply QC filters\n",
    "# analysis_df = apply_qc_filters(analysis_df)\n",
    "\n",
    "print(\"QC filter function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d95e6",
   "metadata": {},
   "source": [
    "## 5. Create PLSC Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333f9026",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plsc_dataframes(df, socioenv_vars, depression_vars, brain_vars, \n",
    "                           covariate_vars, subject_id='src_subject_id'):\n",
    "    \"\"\"\n",
    "    Create FOUR separate dataframes for the two-stage PLSC analysis.\n",
    "    \n",
    "    Stage 1 PLSC:\n",
    "      1. Socioenvironmental (Block 1 / X)\n",
    "      2. Depression (Block 2 / Y)\n",
    "    \n",
    "    Stage 2 (Brain - analyzed separately):\n",
    "      3. Brain ROIs (4 variables)\n",
    "    \n",
    "    Plus:\n",
    "      4. Covariates (for residualization)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Filter to existing variables\n",
    "    existing_socioenv = [v for v in socioenv_vars if v in df.columns]\n",
    "    existing_depression = [v for v in depression_vars if v in df.columns]\n",
    "    existing_brain = [v for v in brain_vars if v in df.columns]\n",
    "    existing_covars = {k: v for k, v in covariate_vars.items() if v in df.columns}\n",
    "    \n",
    "    print(f\"Variables found:\")\n",
    "    print(f\"  Socioenvironmental: {len(existing_socioenv)}/{len(socioenv_vars)}\")\n",
    "    print(f\"  Depression: {len(existing_depression)}/{len(depression_vars)}\")\n",
    "    print(f\"  Brain ROIs: {len(existing_brain)}/{len(brain_vars)}\")\n",
    "    print(f\"  Covariates: {len(existing_covars)}/{len(covariate_vars)}\")\n",
    "    \n",
    "    # Report missing variables\n",
    "    missing_socioenv = [v for v in socioenv_vars if v not in df.columns]\n",
    "    missing_depression = [v for v in depression_vars if v not in df.columns]\n",
    "    missing_brain = [v for v in brain_vars if v not in df.columns]\n",
    "    \n",
    "    if missing_socioenv:\n",
    "        print(f\"\\n  Missing socioenvironmental: {missing_socioenv}\")\n",
    "    if missing_depression:\n",
    "        print(f\"  Missing depression: {missing_depression}\")\n",
    "    if missing_brain:\n",
    "        print(f\"  Missing brain: {missing_brain}\")\n",
    "    \n",
    "    # Create covariate dataframe\n",
    "    covar_cols = [subject_id] + list(existing_covars.values())\n",
    "    covar_df = df[covar_cols].copy().set_index(subject_id)\n",
    "    \n",
    "    # Create socioenvironmental dataframe (PLSC Block 1 / X)\n",
    "    socioenv_df = df[[subject_id] + existing_socioenv].copy().set_index(subject_id)\n",
    "    \n",
    "    # Create depression dataframe (PLSC Block 2 / Y)\n",
    "    depression_df = df[[subject_id] + existing_depression].copy().set_index(subject_id)\n",
    "    \n",
    "    # Create brain dataframe (Stage 2 - 4 ROIs)\n",
    "    brain_df = df[[subject_id] + existing_brain].copy().set_index(subject_id)\n",
    "    \n",
    "    return {\n",
    "        'covariates': covar_df,\n",
    "        'socioenv': socioenv_df,\n",
    "        'depression': depression_df,\n",
    "        'brain': brain_df,\n",
    "        'variable_lists': {\n",
    "            'socioenv': existing_socioenv,\n",
    "            'depression': existing_depression,\n",
    "            'brain': existing_brain,\n",
    "            'covariates': existing_covars,\n",
    "            'brain_labels': BRAIN_ROI_LABELS\n",
    "        }\n",
    "    }\n",
    "\n",
    "print(\"PLSC dataframe creation function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0927ccd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PLSC dataframes\n",
    "# Uncomment when analysis_df is available:\n",
    "\n",
    "# plsc_data = create_plsc_dataframes(\n",
    "#     analysis_df,\n",
    "#     socioenv_vars=SOCIOENV_VARS,\n",
    "#     depression_vars=DEPRESSION_VARS,\n",
    "#     brain_vars=BRAIN_VARS,\n",
    "#     covariate_vars=COVARIATES\n",
    "# )\n",
    "# \n",
    "# print(\"\\nDataframe shapes:\")\n",
    "# print(f\"  Covariates: {plsc_data['covariates'].shape}\")\n",
    "# print(f\"  Socioenvironmental (PLSC Block 1): {plsc_data['socioenv'].shape}\")\n",
    "# print(f\"  Depression (PLSC Block 2): {plsc_data['depression'].shape}\")\n",
    "# print(f\"  Brain - 4 ROIs (Stage 2): {plsc_data['brain'].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6990c15c",
   "metadata": {},
   "source": [
    "## 6. Handle Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf787e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_and_handle_missing(plsc_data, threshold=0.2):\n",
    "    \"\"\"\n",
    "    Assess missing data and apply listwise deletion.\n",
    "    Reports variables with high missingness.\n",
    "    \"\"\"\n",
    "    print(\"Missing data assessment:\")\n",
    "    \n",
    "    for name, df in plsc_data.items():\n",
    "        if name == 'variable_lists':\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n{name.upper()}:\")\n",
    "        for col in df.columns:\n",
    "            pct_missing = df[col].isna().mean() * 100\n",
    "            if pct_missing > 0:\n",
    "                flag = \" ⚠️ HIGH\" if pct_missing > threshold * 100 else \"\"\n",
    "                print(f\"  {col}: {pct_missing:.1f}% missing{flag}\")\n",
    "    \n",
    "    # Get common subjects across all dataframes\n",
    "    common_idx = plsc_data['covariates'].index\n",
    "    for name, df in plsc_data.items():\n",
    "        if name != 'variable_lists':\n",
    "            common_idx = common_idx.intersection(df.dropna().index)\n",
    "    \n",
    "    print(f\"\\nSubjects with complete data: {len(common_idx)}\")\n",
    "    \n",
    "    # Filter all dataframes to common subjects\n",
    "    for name in ['covariates', 'socioenv', 'depression', 'brain']:\n",
    "        plsc_data[name] = plsc_data[name].loc[common_idx]\n",
    "    \n",
    "    return plsc_data\n",
    "\n",
    "# Uncomment when plsc_data is available:\n",
    "# plsc_data = assess_and_handle_missing(plsc_data)\n",
    "\n",
    "print(\"Missing data function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b4fd0c",
   "metadata": {},
   "source": [
    "## 7. Save Dataframes for R Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c5d2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plsc_dataframes(plsc_data, output_dir):\n",
    "    \"\"\"\n",
    "    Save PLSC dataframes to CSV files for R analysis.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Save covariates\n",
    "    plsc_data['covariates'].to_csv(os.path.join(output_dir, 'covariate.csv'))\n",
    "    print(f\"Saved: covariate.csv {plsc_data['covariates'].shape}\")\n",
    "    \n",
    "    # Save socioenvironmental (PLSC Block 1)\n",
    "    plsc_data['socioenv'].to_csv(os.path.join(output_dir, 'clean-socioenv.csv'))\n",
    "    print(f\"Saved: clean-socioenv.csv {plsc_data['socioenv'].shape}\")\n",
    "    \n",
    "    # Save depression (PLSC Block 2)\n",
    "    plsc_data['depression'].to_csv(os.path.join(output_dir, 'clean-depression.csv'))\n",
    "    print(f\"Saved: clean-depression.csv {plsc_data['depression'].shape}\")\n",
    "    \n",
    "    # Save brain data (Stage 2 - 4 ROIs)\n",
    "    plsc_data['brain'].to_csv(os.path.join(output_dir, 'clean-brain-hippo-amyg.csv'))\n",
    "    print(f\"Saved: clean-brain-hippo-amyg.csv {plsc_data['brain'].shape}\")\n",
    "    \n",
    "    # Save variable lists as JSON\n",
    "    with open(os.path.join(output_dir, 'variable_lists.json'), 'w') as f:\n",
    "        json.dump(plsc_data['variable_lists'], f, indent=2)\n",
    "    print(\"Saved: variable_lists.json\")\n",
    "    \n",
    "    print(f\"\\nAll files saved to: {output_dir}\")\n",
    "\n",
    "# Uncomment when plsc_data is available:\n",
    "# save_plsc_dataframes(plsc_data, OUTPUT_DIR)\n",
    "\n",
    "print(\"Save function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d55b7c",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Files to be Created:\n",
    "| File | Contents | Purpose |\n",
    "|------|----------|--------|\n",
    "| `covariate.csv` | Age, sex, race, site, family ID | Residualization |\n",
    "| `clean-socioenv.csv` | 15 socioenvironmental vars | PLSC Block 1 (X) |\n",
    "| `clean-depression.csv` | 8 depression vars | PLSC Block 2 (Y) |\n",
    "| `clean-brain-hippo-amyg.csv` | 4 brain ROIs | Stage 2 (separate) |\n",
    "\n",
    "### Analysis Flow:\n",
    "```\n",
    "STAGE 1: PLSC\n",
    "   Socioenvironmental (15 vars) ←→ Depression (8 vars)\n",
    "   → Identifies latent dimensions\n",
    "   → Extract LV scores\n",
    "\n",
    "STAGE 2: Brain (4 separate analyses)\n",
    "   LV scores ←→ Left Hippocampus (2b>0b)\n",
    "   LV scores ←→ Right Hippocampus (2b>0b)\n",
    "   LV scores ←→ Left Amygdala (emo>neut)\n",
    "   LV scores ←→ Right Amygdala (emo>neut)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45ef66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"DATA PREPARATION SCRIPT READY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\n1. Update ABCD_DATA_PATH at the top of this notebook\")\n",
    "print(f\"2. Run cells to load and merge data\")\n",
    "print(f\"3. Output will be saved to: {OUTPUT_DIR}\")\n",
    "print(f\"4. Then run hippo_amyg_depression_plsc.Rmd in R\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
