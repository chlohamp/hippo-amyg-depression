---
title: "PLSC Analysis: Hippocampus & Amygdala Role in Socioenvironmental Factors and Adolescent Depression"
author: "Chloe Hampson"
date: "`r Sys.Date()`"
output:
  html_document:
    fontsize: 9pt
    theme: united
    code_folding: hide
    toc: true
    toc_float: true
    toc_depth: 6
---

# Overview

**Research Question:** What role do the hippocampus and amygdala play in the association between socioenvironmental factors and adolescent depression?

**Analysis Approach:** Two-stage analysis

## Stage 1: PLSC - Socioenvironmental Factors ↔ Depression Symptoms
- **Block 1 (X matrix):** Socioenvironmental factors (family environment, cultural/social, SES)
- **Block 2 (Y matrix):** Depression symptoms (CBCL, YSR, KSADS)
- Identifies latent dimensions linking specific socioenvironmental patterns to depression patterns

## Stage 2: Brain-Behavior Analysis
- Correlate PLSC latent variable scores with hippocampus/amygdala activation
- Determines whether brain function mediates/moderates the socio-depression association
- Can also run secondary PLSC: Brain ↔ PLSC latent scores

---

```{r}
# ---- KNIT-SAFE SETUP ----
# Ensures Knit uses your project folder as the working directory.
knitr::opts_knit$set(root.dir = "/Users/chloehampson/Desktop/hippo-amyg-depression")

# Chunk defaults (adjust if you want messages/warnings)
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE
)

options(stringsAsFactors = FALSE)

```


## Import Libraries

```{r}
rm(list = ls()) # Clear environment
graphics.off() # Clear all plots

#install.packages("devtools") # decomment this line if devtools is not yet intalled
#devtools::install_github('HerveAbdi/PTCA4CATA', dependencies = TRUE, force = TRUE)

# Load necessary libraries
library(tidyverse) # Core tidyverse packages
library(ExPosition) # Multivariate data analysis
library(TExPosition) # Tensor-based ExPosition analysis
# library(TInPosition)  # Uncomment if needed and installed
library(PTCA4CATA) # Permutation Tests for CATA
library(data4PCCAR) # Example datasets for PCA
library(dplyr) # Data manipulation
library(plyr) # Data manipulation (load first to avoid conflicts)
library(corrplot) # Correlation plots
library(ggplot2) # Data visualization
library(cowplot) # Plot arrangement
library(readr) # Reading data files
library(gridExtra) # Arrange grid-based visualizations
library(grid) # Low-level graphics system
library(here) # Relative file paths
library(psych) # Psychometric tools
library(car)
library(kableExtra)
```


---

## Load Data

**Data prepared using `data_preparation.ipynb`**

Four dataframes:
1. `covariate.csv` - Covariates for residualization
2. `clean-socioenv.csv` - Socioenvironmental variables (Block 1 for PLSC)
3. `clean-depression.csv` - Depression symptoms (Block 2 for PLSC)
4. `clean-brain-hippo-amyg.csv` - Hippocampus & Amygdala activation (for Stage 2)

```{r load_data, message=FALSE}
# Because we set knitr root.dir to the project folder,
# we can use RELATIVE paths safely when knitting.
data_dir <- "derivatives"
fig_dir  <- file.path(data_dir, "figures")
out_dir  <- data_dir

# Create figures directory if it doesn't exist
if (!dir.exists(fig_dir)) {
  dir.create(fig_dir, recursive = TRUE)
}

# Load datasets (cleaned CSVs from Python preprocessing)
covar_df      <- readr::read_csv(file.path(data_dir, "demographics_clean.csv"))
socioenv_df   <- readr::read_csv(file.path(data_dir, "socioenvironment_clean.csv"))
depression_df <- readr::read_csv(file.path(data_dir, "depression_clean.csv"))
brain_df      <- readr::read_csv(file.path(data_dir, "task-FC_clean.csv"))

# Quick sanity checks (optional but helpful)
stopifnot(nrow(covar_df) > 0, nrow(socioenv_df) > 0, nrow(depression_df) > 0, nrow(brain_df) > 0)

# Print dimensions
cat("Rows x Cols\n")
cat("covar_df:     ", nrow(covar_df), "x", ncol(covar_df), "\n")
cat("socioenv_df:  ", nrow(socioenv_df), "x", ncol(socioenv_df), "\n")
cat("depression_df:", nrow(depression_df), "x", ncol(depression_df), "\n")
cat("brain_df:     ", nrow(brain_df), "x", ncol(brain_df), "\n")

```


## Performing residualization 

###  MLRM for resting-state data

```{r}
## Socioenvironmental data residualization
# dependent variables
Group1.Y <- as.matrix(socioenv_df)
View(Group1.Y)

# independent variables/covariates
Group1.X <- covar_df
View(Group1.X)
```



```{r}
# Multiple regression model
lm.Group1 <- lm(Group1.Y ~ Group1.X$ab_p_demo_age +
  as.factor(Group1.X$ab_g_stc__cohort_sex) +
  as.factor(Group1.X$ab_g_stc__cohort_ethnrace__meim) +
  as.factor(Group1.X$ab_g_stc__cohort_race__nih) +
  as.factor(Group1.X$ab_g_dyn__design_site) +
  as.factor(Group1.X$mr_y_adm__info__dev_manufact) +
  Group1.X$ab_g_stc__design_id__fam, na.action = na.omit)


# R.square -> how well the model explains the variation in the data which is not random
# Theorotical model performace is defined as R square

Group1_residuals <- data.frame()
Group1_residuals <- as.data.frame(lm.Group1$residuals)
```

### MLRM for sociocultural data

```{r echo=TRUE}
Group2.Y <- as.matrix(depression_df)

# Multiple regression model
lm.Group2 <- lm(Group2.Y ~ Group1.X$ab_p_demo_age +
  as.factor(Group1.X$ab_g_stc__cohort_sex) +
  as.factor(Group1.X$ab_g_stc__cohort_ethnrace__meim) +
  as.factor(Group1.X$ab_g_stc__cohort_race__nih) +
  as.factor(Group1.X$ab_g_dyn__design_site) +
  as.factor(Group1.X$mr_y_adm__info__dev_manufact) +
  Group1.X$ab_g_stc__design_id__fam, na.action = na.omit)


# keep if we decide this is how we want to deal with missing data #,na.action = na.omit)
# Run VIF to check for multicollinearity
summary(lm.Group2)

Group2_residuals <- data.frame()
Group2_residuals <- as.data.frame(lm.Group2$residuals)

```


## PLSC Analysis

### 1. Correlation plots

```{r}
# Input data for PLSC
data1 <- as.data.frame(Group1_residuals)
data2 <- as.data.frame(Group2_residuals)


# Compute the covariance matrix

XY.cor.pearson <- cor(data2, data1)

# Save the plot as a PNG file with higher resolution
corr <- paste0(fig_dir, "correlation_plot.png")


# Create the plot
png(corr, width = 1200, height = 800, res = 300) # Increase res to 300 dpi



# for full
corrplot(XY.cor.pearson,
  is.corr = FALSE, # Treat as raw data
  method = "color",
  col.lim = c(-0.25, 0.25), # Set color limits
  tl.cex = 0.2, tl.col = "black", # Smaller text labels
  cl.pos = "b", cl.cex = 0.3, # Smaller legend text
  title = "Pearson Correlation",
  cex.main = 0.8, # Adjust title text size
  mar = c(0, 0, 1, 0), # Smaller margins
  lwd = 0.1, # Thinner lines
  col = colorRampPalette(c("darkred", "white", "midnightblue"))(6)
)
dev.off() # Close the device

```


### 2. Package details

```{r}
tepPLS(data1, data2,
  center1 = TRUE,
  scale1 = "SS1",
  center2 = TRUE,
  scale2 = "SS1",
  DESIGN = NULL,
  make_design_nominal = TRUE,
  graphs = TRUE,
  k = 0
)
```

tepPLS(DATA1, DATA2, center1 = TRUE, scale1 = "SS1", center2 = TRUE, scale2 = "SS1", DESIGN = NULL, make_design_nominal = TRUE, graphs = TRUE, k = 0)

DATA1 : Data matrix 1 (X)

DATA2 : Data matrix 2 (Y)

center1 : a boolean, vector, or string to center DATA1. See expo.scale for details.

scale1 : a boolean, vector, or string to scale DATA1. See expo.scale for details.

center2 : a boolean, vector, or string to center DATA2. See expo.scale for details.

scale2 : a boolean, vector, or string to scale DATA2. See expo.scale for details.

DESIGN : a design matrix to indicate if rows belong to groups.

make_design_nominal	: a boolean. If TRUE (default), DESIGN is a vector that indicates groups (and will be dummy-coded). If FALSE, DESIGN is a dummy-coded matrix.

graphs : a boolean. If TRUE (default), graphs and plots are provided (via tepGraphs)

k	: number of components to return.



```{r echo=TRUE}
# Extract design variable and ensure it's a factor (nominal)
data.design <- as.factor(covar_df$ab_g_dyn__design_site)

# Convert to a matrix for PLSC input
data.design.vec <- as.matrix(data.design)
rownames(data.design.vec) <- covar_df$participant_id

# Run PLSC analysis
pls.res <- tepPLS(
  data1,
  data2,
  DESIGN = data.design.vec,
  make_design_nominal = TRUE,
  graphs = FALSE
)

summary(pls.res)
```

### 3. Number of Dimensions

The scree plot shows a weird pattern because the null hypothesis is that there is no correlation between the tables (Null = 0) 
Hence eigenvalues greater than zero become significant. 

The results of the permutation test gives us the eigenvalues.

```{r echo=TRUE}
# no.of eigenvalues
nL <- min(ncol(data1), ncol(data2))

# Applying permutation test to the input data for PLSC
# should do 10000 iterations
resPerm4PLSC <- perm4PLSC(data1, # First Data matrix
  data2, # Second Data matrix
  permType = "byColumns",
  nIter = 10000 # How many iterations
)
print(resPerm4PLSC)

```

```{r}
scree_df <- data.frame(row.names = colnames(socio_df))
scree_df$eigens <- pls.res$TExPosition.Data$eigs
scree_df$pEigens <- resPerm4PLSC$pEigenvalues


write.csv(
  scree_df,
  file = paste0(fig_dir, "/rest-scree_values_", resPerm4PLSC$pOmnibus, "-components.csv")
)

# Set the file path for saving the plot
png(file.path(fig_dir, "PLSC_Scree_Plot.png"), width = 1200, height = 800, res = 100)

# Create the scree plot
my.scree <- PlotScree(
  ev = pls.res$TExPosition.Data$eigs,
  p.ev = resPerm4PLSC$pEigenvalues,
  title = "PLSC Scree Plot",
  plotKaiser = TRUE,
  col.ns = "black",
  col.sig = "red"
)

# Calculate and round eigenvalues to 2 decimal places
eig <- t(round(pls.res$TExPosition.Data$eigs, 2))
peig <- t(resPerm4PLSC$pEigenvalues)
# Create the names for the dimensions
names <- paste0("dim", seq(1:20))
# Create the table and print it explicitly
eig_table <- kable(eig, col.names = names(pls.res$TExPosition.Data$eigs)) %>%
  kable_styling()
peig_table <- kable(peig, col.names = names(resPerm4PLSC$pEigenvalues)) %>%
  kable_styling()
# Explicitly print the table to the console
print(eig_table) # Ensure the table is printed
print(peig_table)

# Close the PNG device
dev.off()
```



# These are the loadings obtained after performing SVD(R) on correlation matrix.


```{r}
# generating bar plots for loadings of Depression data table
Q.data2 <- pls.res$TExPosition.Data$pdq$q
# generating bar plots for loadings of Sociocultural data table
P.data1 <- pls.res$TExPosition.Data$pdq$p

# saving the loading table into excel file.
depression_loadings <- as.data.frame(Q.data2)
socioenv_loadings <- as.data.frame(P.data1)
```
```{r}
# Looking into what the resBootPLSC is giving us
resBoot4PLSC <- Boot4PLSC(data1, # First Data matrix
  data2, # Second Data matrix
  nIter = 10000, # How many iterations
  Fi = pls.res$TExPosition.Data$fi,
  Fj = pls.res$TExPosition.Data$fj,
  nf2keep = 5, #determines number of dimensions that go into bootstrap
  critical.value = 2.5,
  # To be implemented later
  # has no effect currently
  alphaLevel = 0.5
)

resBoot4PLSC

```

```{r}

BR.I <- resBoot4PLSC$bootRatios.i
BR.J <- resBoot4PLSC$bootRatios.j


# saving the bootstrap rations into excel

depression_bootstrap <- as.data.frame(BR.J)
socioenv_bootstrap <- as.data.frame(BR.I)

socioenv_res <- cbind.data.frame(socioenv_loadings, socioenv_bootstrap)
depression_res <- cbind.data.frame(depression_loadings, depression_bootstrap)

write.csv(socioenv_res, paste(out_dir,
  "rni-sociocult_Q-components.csv",
  sep = "/"
), row.names = TRUE)

write.csv(depression_res, paste(out_dir,
  "rni-depression_P-components.csv",
  sep = "/"
), row.names = TRUE)

write.csv(pls.res$TExPosition.Data$lx, paste(out_dir,
  "rniXrsfc_lx-base.csv",
  sep = "/"
), row.names = TRUE)

write.csv(pls.res$TExPosition.Data$ly, paste(out_dir,
  "rniXrsfc_ly-base.csv",
  sep = "/"
), row.names = TRUE)

```

```{r}
# Determine number of significant dimensions
# Find the last (highest) dimension with p < 0.01
laDim <- 1  # Default to dimension 1

if (resPerm4PLSC$pOmnibus < 0.01) {
  # Find the highest dimension that is still significant
  significant_dims <- which(resPerm4PLSC$pEigenvalues < 0.01)
  
  if (length(significant_dims) > 0) {
    laDim <- max(significant_dims)  # Take the highest significant dimension
  }
  
  cat("Omnibus test p-value:", resPerm4PLSC$pOmnibus, "\n")
  cat("Significant dimensions (p < 0.01):", significant_dims, "\n")
  cat("Number of significant dimensions:", length(significant_dims), "\n")
  cat("Using dimension:", laDim, "for bootstrap ratio plots\n")
} else {
  cat("Omnibus test not significant (p =", resPerm4PLSC$pOmnibus, ")\n")
  cat("Using dimension 1 by default\n")
}

print(paste("Selected dimension:", laDim))
```


```

```{r}
# Bootstrap ratios plots for dimensions 1 and 3
dimensions_to_plot <- c(1, 2, 3, 4)

for (dim in dimensions_to_plot) {
  cat("Creating bootstrap ratio plots for Dimension", dim, "\n")
  
  # Save the plot for BR.I (Socioenvironment - Table 1)
  png(file.path(fig_dir, paste0("Bootstrap_Ratio_BRI_Dim", dim, ".png")), 
      width = 2000, height = 1200, res = 200)
  
  plot_BRI <- PrettyBarPlot2(BR.I[, dim],
    threshold = 3,
    font.size = 4,
    ylab = "Bootstrap ratios"
  ) + ggtitle(paste0("Component ", dim), subtitle = "Socioenvironment Variables")
  
  print(plot_BRI)
  dev.off() # Close the PNG device for BR.I
  
  # Save the plot for BR.J (Depression - Table 2)  
  png(file.path(fig_dir, paste0("Bootstrap_Ratio_BRJ_Dim", dim, ".png")), 
      width = 2000, height = 1200, res = 200)
  
  plot_BRJ <- PrettyBarPlot2(BR.J[, dim],
    threshold = 3,
    font.size = 4,
    ylab = "Bootstrap ratios"
  ) + ggtitle(paste0("Component ", dim), subtitle = "Depression Variables")
  
  print(plot_BRJ)
  dev.off() # Close the PNG device for BR.J
  
  cat("✓ Saved bootstrap ratio plots for Dimension", dim, "\n\n")
}

# Display which dimension was automatically selected
cat("Note: Automatically selected dimension based on significance:", laDim, "\n")
cat("Manually plotting dimensions:", paste(dimensions_to_plot, collapse = ", "), "\n")
```

### Percent Variance
```{r echo=TRUE}
# CORRECT: Calculate percent variance from eigenvalues, not bootstrap ratios
eigenvalues <- pls.res$TExPosition.Data$eigs

# Percent variance explained by each component
pctVar_explained <- (eigenvalues / sum(eigenvalues)) * 100

# Cumulative percent variance
cumVar_explained <- cumsum(pctVar_explained)

# Create a summary table
variance_table <- data.frame(
  Component = paste0("Dim", 1:length(eigenvalues)),
  Eigenvalue = round(eigenvalues, 4),
  Percent_Variance = round(pctVar_explained, 2),
  Cumulative_Variance = round(cumVar_explained, 2)
)

print("Percent Variance Explained by Each Component:")
print(variance_table)

# For loadings contribution (optional - different from explained variance)
# This shows how much each variable contributes to bootstrap ratio variance
ssq.BR.I <- colSums(BR.I^2)
ssq.BR.J <- colSums(BR.J^2)

# Percent of total bootstrap ratio variance (NOT explained variance)
pctContrib.BR.I <- ssq.BR.I / sum(ssq.BR.I) * 100
pctContrib.BR.J <- ssq.BR.J / sum(ssq.BR.J) * 100

print("Bootstrap Ratio Contribution (Variable Stability):")
print("Block I (Socioenvironment):")
print(round(pctContrib.BR.I, 2))
print("Block J (Depression):")
print(round(pctContrib.BR.J, 2))

# Key results for first component
cat("\n=== SUMMARY FOR DIMENSION 1 ===\n")
cat("Explained Variance:", round(pctVar_explained[1], 2), "%\n")
cat("Eigenvalue:", round(eigenvalues[1], 4), "\n")
```